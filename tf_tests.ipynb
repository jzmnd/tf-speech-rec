{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import seaborn as sns\n",
    "import librosa\n",
    "import librosa.display\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Tensorflow setup\n",
    "sess = None\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "def reset_vars():\n",
    "    \"\"\"Initializes all tf variables\"\"\"\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "def reset_tf():\n",
    "    \"\"\"Closes the current tf session and opens new session\"\"\"\n",
    "    global sess\n",
    "    if sess:\n",
    "        sess.close()\n",
    "    tf.reset_default_graph()\n",
    "    sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Functions to initialize weights and biases\n",
    "def weight_variable(shape):\n",
    "    \"\"\"Creates a variable of size shape with random small positive numbers\"\"\"\n",
    "    initial = tf.truncated_normal(shape, stddev=0.01)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "def bias_variable(shape):\n",
    "    \"\"\"Creates a variable of size shape with a constant small positive number\"\"\"\n",
    "    initial = tf.constant(0.01, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Conv2d, max pooling, and dropout wrapper functions for simplicity\n",
    "def conv2d(x, W, sx=1, sy=1):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, sx, sy, 1], padding='SAME')\n",
    "\n",
    "\n",
    "def max_pool_2d(x, k=2):\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')\n",
    "\n",
    "\n",
    "def dropout(x, d, is_training):\n",
    "    if is_training is not None:\n",
    "        return tf.nn.dropout(x, d)\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "LABELS_REQUIRED = ['yes', 'no', 'up', 'down', 'left',\n",
    "                   'right', 'on', 'off', 'stop', 'go',\n",
    "                   'silence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "BITRATE = 16                      # Bit rate\n",
    "SAMRATE = 16000                   # Sample rate (Hz)\n",
    "SAMTIME = 1000.0 / SAMRATE        # Sample time (ms)\n",
    "MAXAMPS = float(2**BITRATE / 2)   # Max samples amplitute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "num2label = {i+1:l for i, l in enumerate(LABELS_REQUIRED)}\n",
    "num2label[0] = 'unknown'\n",
    "label2num = {v:k for k, v in num2label.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "reset_tf()\n",
    "\n",
    "# Model parameters\n",
    "melspec_shape = (64, 126)                           # Shape of Mel spectrum data (f x t)\n",
    "melspec_size = melspec_shape[0] * melspec_shape[1]\n",
    "mfcc_shape = (19, 126)                              # Shape of MFCC data\n",
    "mfcc_size = mfcc_shape[0] * mfcc_shape[1]\n",
    "sf_size = 122                                       # Length of 1D feature arrays e.g. ZCR and RMSE\n",
    "\n",
    "n_classes = len(label2num)\n",
    "\n",
    "batch_size = 50\n",
    "num_iterations = 5000\n",
    "display_step = 100\n",
    "\n",
    "learning_rate = 2e-4\n",
    "dropout_prob_value = 0.60                           # Dropout, probability to keep units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total feature size:  10580\n"
     ]
    }
   ],
   "source": [
    "print \"Total feature size:  {}\".format(melspec_size + mfcc_size + sf_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# MODEL\n",
    "def conv_net_speech_model(x_mel, x_mfcc, x_zcr, x_rmse, dropout_prob=None, is_training=False):\n",
    "    \n",
    "    #======================================================\n",
    "    # Setup the parameters for the model\n",
    "    #======================================================\n",
    "    \n",
    "    # Mel Spectrogram input size\n",
    "    f_size = melspec_shape[0]\n",
    "    t_size = melspec_shape[1]\n",
    "\n",
    "    # Parameters for Conv layer 1 filter\n",
    "    filter_size_t = 32\n",
    "    filter_size_f = 8\n",
    "    filter_count = 256\n",
    "    filter_stride_t = 1\n",
    "    filter_stride_f = 4\n",
    "    \n",
    "    # Paramaters for FC layers\n",
    "    fc_output_channels_1 = 128\n",
    "    fc_output_channels_2 = 128\n",
    "    fc_output_channels_3 = n_classes\n",
    "    \n",
    "    # Number of elements in the first FC layer\n",
    "    fc_element_count = int(filter_count \\\n",
    "                       * int(1 + (t_size - filter_size_t) / filter_stride_t) \\\n",
    "                       * int(1 + (f_size - filter_size_f) / filter_stride_f))\n",
    "    \n",
    "    #======================================================\n",
    "    # Setup dictionaries containing weights and biases\n",
    "    #======================================================\n",
    "    \n",
    "    weights = {\n",
    "        'wconv1': weight_variable([filter_size_t, filter_size_f, 1, filter_count]),\n",
    "        'wfc1': weight_variable([fc_element_count, fc_output_channels_1]),\n",
    "        'wfc2': weight_variable([fc_output_channels_1, fc_output_channels_2]),\n",
    "        'wfc3': weight_variable([fc_output_channels_2, fc_output_channels_3]),\n",
    "    }\n",
    "    biases = {\n",
    "        'bconv1': bias_variable([filter_count]),\n",
    "        'bfc1': bias_variable([fc_output_channels_1]),\n",
    "        'bfc2': bias_variable([fc_output_channels_2]),\n",
    "        'bfc3': bias_variable([fc_output_channels_3]),\n",
    "    }\n",
    "    \n",
    "    #======================================================\n",
    "    # Model definition and calculations\n",
    "    #======================================================\n",
    "    \n",
    "    # Reshape input to [audio file number, time size, freq size, channel]\n",
    "    x_mel_rs = tf.reshape(x_mel, [-1, t_size, f_size, 1])\n",
    "    \n",
    "    # Layer 1: first Conv layer, BiasAdd and ReLU\n",
    "    x_mel_1 = tf.nn.relu(conv2d(x_mel_rs, weights['wconv1'],\n",
    "                                sx=filter_stride_t,\n",
    "                                sy=filter_stride_f) + biases['bconv1'])\n",
    "    \n",
    "    # Dropout 1:\n",
    "    x_mel_dropout_1 = dropout(x_mel_1, dropout_prob, is_training)\n",
    "    \n",
    "    # Flatten layers\n",
    "    x_mel_1_rs = tf.reshape(x_mel_dropout_1, [-1, fc_element_count])\n",
    "\n",
    "    # Layer 2: first FC layer\n",
    "    x_mel_2 = tf.matmul(x_mel_1_rs, weights['wfc1']) + biases['bfc1']\n",
    "    \n",
    "    # Dropout 2:\n",
    "    x_mel_dropout_2 = dropout(x_mel_2, dropout_prob, is_training)\n",
    "    \n",
    "    # Layer 3: second FC layer\n",
    "    x_mel_3 = tf.matmul(x_mel_dropout_2, weights['wfc2']) + biases['bfc2']\n",
    "    \n",
    "    # Dropout 3:\n",
    "    x_mel_dropout_3 = dropout(x_mel_3, dropout_prob, is_training)\n",
    "    \n",
    "    # Layer 4: third FC layer\n",
    "    x_mel_output = tf.matmul(x_mel_dropout_3, weights['wfc3']) + biases['bfc3']\n",
    "    \n",
    "    return x_mel_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Placeholder variables input\n",
    "x_mel = tf.placeholder(tf.float32, [None, melspec_size], name='x_mel')\n",
    "x_mfcc = tf.placeholder(tf.float32, [None, mfcc_size], name='x_mfcc')\n",
    "x_zcr = tf.placeholder(tf.float32, [None, sf_size], name='x_zcr')\n",
    "x_rmse = tf.placeholder(tf.float32, [None, sf_size], name='x_rsme')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Placeholder variables output\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, n_classes], name='y_true')\n",
    "y_true_class = tf.argmax(y_true, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Dropout keep probability and training flag\n",
    "dropout_prob = tf.placeholder(tf.float32, name='dropout_prob')\n",
    "is_training = tf.placeholder(tf.bool, name=\"is_training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Prediction from model\n",
    "y_pred = conv_net_speech_model(x_mel, x_mfcc, x_zcr, x_rmse, dropout_prob=dropout_prob, is_training=is_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'accuracy:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross entropy loss function with softmax then takes mean\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_pred, labels=y_true))\n",
    "tf.summary.scalar('loss', loss)\n",
    "\n",
    "# Train and backprop gradients function\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "# Evaluation and accuracy\n",
    "y_pred_class = tf.argmax(y_pred, 1)\n",
    "correct_prediction = tf.equal(y_pred_class, y_true_class)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "tf.summary.scalar('accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Merge all summaries\n",
    "merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Initialize\n",
    "reset_vars()\n",
    "\n",
    "# Set path to summary logs\n",
    "now = datetime.now()\n",
    "logs_path = now.strftime(\"%Y%m%d-%H%M%S\") + '/summaries'\n",
    "\n",
    "# Create summary writers\n",
    "train_writer = tf.summary.FileWriter(logs_path + '/train', graph=tf.get_default_graph())\n",
    "test_writer = tf.summary.FileWriter(logs_path + '/test', graph=tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def next_batch(num):\n",
    "    \"\"\"Return a total of 'num' random samples\"\"\"\n",
    "\n",
    "    #data_list = # TODO: get files, do signal processing and return features\n",
    "\n",
    "    idx = np.arange(0, len(data_list[0]))\n",
    "    idx = np.random.choice(idx, size=num, replace=False)\n",
    "    \n",
    "    data_list_batch = []\n",
    "    for data in data_list:    \n",
    "        data_list_batch.append(data[idx])\n",
    "\n",
    "    return data_list_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TRAINING\n",
    "def run_optimize(num_iterations, min_loss=0):\n",
    "    # Start-time\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i in xrange(num_iterations):\n",
    "        \n",
    "        # Get the training batch\n",
    "        x_mel_batch, x_mfcc_batch, x_zcr_batch, x_rmse_batch, y_true_batch = next_batch(batch_size)\n",
    "\n",
    "        # Training optimization\n",
    "        sess.run(optimizer, feed_dict={x_mel: x_mel_batch,\n",
    "                                       x_mfcc: x_mfcc_batch,\n",
    "                                       x_zcr: x_zcr_batch,\n",
    "                                       x_rmse: x_rmse_batch, \n",
    "                                       y_true: y_true_batch,\n",
    "                                       dropout_prob: dropout_prob_value,\n",
    "                                       is_training: True})\n",
    "        \n",
    "        if (i % display_step == 0) or (i == num_iterations - 1):\n",
    "            # Training summary\n",
    "            train_summary, loss_train, acc_train = sess.run([merged, loss, accuracy],\n",
    "                                                            feed_dict={x_mel: x_mel_batch,\n",
    "                                                                       x_mfcc: x_mfcc_batch,\n",
    "                                                                       x_zcr: x_zcr_batch,\n",
    "                                                                       x_rmse: x_rmse_batch,\n",
    "                                                                       y_true: y_true_batch,\n",
    "                                                                       dropout_prob: dropout_prob_value,\n",
    "                                                                       is_training: False})\n",
    "            train_writer.add_summary(train_summary, i + 1)\n",
    "            \n",
    "            # Testing summary\n",
    "            test_summary, loss_test, acc_test = sess.run([merged, loss, accuracy],\n",
    "                                                         feed_dict={x_mel: x_mel_test,\n",
    "                                                                    x_mfcc: x_mfcc_test,\n",
    "                                                                    x_zcr: x_zcr_test,\n",
    "                                                                    x_rmse: x_rmse_test,\n",
    "                                                                    y_true: y_true_test,\n",
    "                                                                    dropout_prob: dropout_prob_value,\n",
    "                                                                    is_training: False})\n",
    "            test_writer.add_summary(test_summary, i + 1)\n",
    "            \n",
    "            # Display message\n",
    "            msg = \"  OPTIMIZE STEP: {:6d}, LOSS, {:.6f}, ACC: {:.6f}\"\n",
    "            print(msg.format(i + 1, loss_test, acc_test))\n",
    "    \n",
    "            # Check if loss is below minimum\n",
    "            if loss_train < min_loss:\n",
    "                break\n",
    "    \n",
    "    # End-time\n",
    "    end_time = time.time()\n",
    "    print \"Time usage: {}\".format(timedelta(seconds=int(round(end_time - start_time))))    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
