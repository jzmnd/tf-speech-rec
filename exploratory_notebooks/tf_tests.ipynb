{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import io_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Load custom libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import config as cfg\n",
    "from dataload import load_data, load_batch\n",
    "from preprocessing import signalProcessBatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Tensorflow setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Tensorflow setup\n",
    "sess = None\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "def reset_vars():\n",
    "    \"\"\"Initializes all tf variables\"\"\"\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "def reset_tf():\n",
    "    \"\"\"Closes the current tf session and opens new session\"\"\"\n",
    "    global sess\n",
    "    if sess:\n",
    "        sess.close()\n",
    "    tf.reset_default_graph()\n",
    "    sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Functions to initialize weights and biases\n",
    "def weight_variable(shape, name):\n",
    "    \"\"\"Creates a variable of size shape with random small positive numbers\"\"\"\n",
    "    initial = tf.truncated_normal(shape, stddev=0.01)\n",
    "    return tf.Variable(initial, name=name)\n",
    "\n",
    "\n",
    "def bias_variable(shape, name):\n",
    "    \"\"\"Creates a variable of size shape with a constant small positive number\"\"\"\n",
    "    initial = tf.constant(0.01, shape=shape)\n",
    "    return tf.Variable(initial, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Conv2d, max pooling, and dropout wrapper functions for simplicity (No padding)\n",
    "def conv2d(x, W, sx=1, sy=1):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, sx, sy, 1], padding='VALID')\n",
    "\n",
    "\n",
    "def max_pool_2d(x, k=2):\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='VALID')\n",
    "\n",
    "\n",
    "def dropout(x, d, is_training):\n",
    "    if is_training is not None:\n",
    "        return tf.nn.dropout(x, d)\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "reset_tf()\n",
    "\n",
    "# Model parameters\n",
    "melspec_shape = (122, 64)                           # Shape of Mel spectrum data (t x f)\n",
    "melspec_size = melspec_shape[0] * melspec_shape[1]\n",
    "mfcc_shape = (122, 13)                              # Shape of MFCC data (t x mfcc)\n",
    "mfcc_size = mfcc_shape[0] * mfcc_shape[1]\n",
    "sf_size = 122                                       # Length of 1D feature arrays e.g. ZCR and RMSE\n",
    "\n",
    "n_classes = len(cfg.NUM2LABEL)\n",
    "\n",
    "batch_size = 128\n",
    "silence_size = 4\n",
    "num_iterations = 5000\n",
    "display_step = 100\n",
    "checkpoint_step = 500\n",
    "\n",
    "learning_rate = 1e-3\n",
    "dropout_prob_value = 0.50                           # Dropout, probability to keep units\n",
    "\n",
    "noise_factor_value = 0.1\n",
    "noise_frac_value = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total feature size:  9516\n"
     ]
    }
   ],
   "source": [
    "print \"Total feature size:  {}\".format(melspec_size + mfcc_size + sf_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# MODEL\n",
    "def conv_net_speech_model(x_mel_in, x_mfcc_in, x_zcr_in, x_rmse_in, dropout_prob=None, is_training=False):\n",
    "    \n",
    "    #======================================================\n",
    "    # Setup the parameters for the model\n",
    "    #======================================================\n",
    "    \n",
    "    # Mel Spectrogram input size\n",
    "    t_size = melspec_shape[0]\n",
    "    f_size = melspec_shape[1]\n",
    "\n",
    "    # Parameters for Conv layer 1 filter\n",
    "    filter_size_t = 61\n",
    "    filter_size_f = 8\n",
    "    filter_count = 180\n",
    "    filter_stride_t = 1\n",
    "    filter_stride_f = 4\n",
    "    \n",
    "    # Paramaters for FC layers\n",
    "    fc_output_channels_1 = 128\n",
    "    fc_output_channels_2 = 128\n",
    "    fc_output_channels_3 = n_classes\n",
    "    \n",
    "    # Number of elements in the first FC layer\n",
    "    fc_element_count = int(filter_count \\\n",
    "                       * int(1 + (t_size - filter_size_t) / filter_stride_t) \\\n",
    "                       * int(1 + (f_size - filter_size_f) / filter_stride_f))\n",
    "    \n",
    "    #======================================================\n",
    "    # Setup dictionaries containing weights and biases\n",
    "    #======================================================\n",
    "    \n",
    "    weights = {\n",
    "        'wconv1': weight_variable([filter_size_t, filter_size_f, 1, filter_count], 'wconv1'),\n",
    "        'wfc1': weight_variable([fc_element_count, fc_output_channels_1], 'wfc1'),\n",
    "        'wfc2': weight_variable([fc_output_channels_1, fc_output_channels_2], 'wfc2'),\n",
    "        'wfc3': weight_variable([fc_output_channels_2, fc_output_channels_3], 'wfc3'),\n",
    "    }\n",
    "    biases = {\n",
    "        'bconv1': bias_variable([filter_count], 'bconv1'),\n",
    "        'bfc1': bias_variable([fc_output_channels_1], 'bfc1'),\n",
    "        'bfc2': bias_variable([fc_output_channels_2], 'bfc2'),\n",
    "        'bfc3': bias_variable([fc_output_channels_3], 'bfc3'),\n",
    "    }\n",
    "    \n",
    "    #======================================================\n",
    "    # Model definition and calculations\n",
    "    #======================================================\n",
    "    \n",
    "    # Reshape input to [audio file number, time size, freq size, channel]\n",
    "    x_mel_rs = tf.reshape(x_mel_in, [-1, t_size, f_size, 1])\n",
    "    \n",
    "    # Layer 1: first Conv layer, BiasAdd and ReLU\n",
    "    x_mel_1 = tf.nn.relu(conv2d(x_mel_rs, weights['wconv1'],\n",
    "                                sx=filter_stride_t,\n",
    "                                sy=filter_stride_f) + biases['bconv1'])\n",
    "\n",
    "    # Dropout 1:\n",
    "    x_mel_dropout_1 = dropout(x_mel_1, dropout_prob, is_training)\n",
    "    \n",
    "    # Flatten layers\n",
    "    x_mel_1_rs = tf.reshape(x_mel_dropout_1, [-1, fc_element_count])\n",
    "\n",
    "    # Layer 2: first FC layer\n",
    "    x_mel_2 = tf.matmul(x_mel_1_rs, weights['wfc1']) + biases['bfc1']\n",
    "    \n",
    "    # Dropout 2:\n",
    "    x_mel_dropout_2 = dropout(x_mel_2, dropout_prob, is_training)\n",
    "    \n",
    "    # Layer 3: second FC layer\n",
    "    x_mel_3 = tf.matmul(x_mel_dropout_2, weights['wfc2']) + biases['bfc2']\n",
    "    \n",
    "    # Dropout 3:\n",
    "    x_mel_dropout_3 = dropout(x_mel_3, dropout_prob, is_training)\n",
    "    \n",
    "    # Layer 4: third FC layer\n",
    "    x_mel_output = tf.matmul(x_mel_dropout_3, weights['wfc3']) + biases['bfc3']\n",
    "    \n",
    "    return x_mel_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Placeholders for signals preprocessing inputs\n",
    "X_data = tf.placeholder(tf.float32, [None, cfg.SAMRATE], name='X_data')\n",
    "\n",
    "noise_factor = tf.placeholder(tf.float32, shape=(), name='noise_factor')\n",
    "noise_frac = tf.placeholder(tf.float32, shape=(), name='noise_frac')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Define the audio features\n",
    "x_mfcc, x_mel, x_zcr, x_rmse = signalProcessBatch(X_data,\n",
    "                                                  noise_factor=noise_factor,\n",
    "                                                  noise_frac=noise_frac,\n",
    "                                                  window=512,\n",
    "                                                  maxamps=cfg.MAXAMPS, sr=cfg.SAMRATE,\n",
    "                                                  num_mel_bins=64, num_mfccs=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Placeholder variables output (1-hot vectors of size n_classes)\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, n_classes], name='y_true')\n",
    "y_true_class = tf.argmax(y_true, 1, name='y_true_class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Dropout keep probability and training flag\n",
    "dropout_prob = tf.placeholder(tf.float32, shape=(), name='dropout_prob')\n",
    "is_training = tf.placeholder(tf.bool, name=\"is_training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Prediction from model\n",
    "y_pred = conv_net_speech_model(x_mel, x_mfcc, x_zcr, x_rmse, dropout_prob=dropout_prob, is_training=is_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'accuracy:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross entropy loss function with softmax then takes mean\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_pred, labels=y_true))\n",
    "tf.summary.scalar('loss', loss)\n",
    "\n",
    "# Train and backprop gradients function\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "# Evaluation and accuracy\n",
    "y_pred_class = tf.argmax(y_pred, 1, name='y_pred_class')\n",
    "correct_prediction = tf.equal(y_pred_class, y_true_class)\n",
    "confusion_matrix = tf.confusion_matrix(y_true_class, y_pred_class, num_classes=n_classes)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "tf.summary.scalar('accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Merge all summaries\n",
    "merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Saver for checkpoints\n",
    "saver = tf.train.Saver(tf.global_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'wconv1:0' shape=(61, 8, 1, 180) dtype=float32_ref>,\n",
       " <tf.Variable 'wfc1:0' shape=(167400, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'wfc2:0' shape=(128, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'wfc3:0' shape=(128, 12) dtype=float32_ref>,\n",
       " <tf.Variable 'bconv1:0' shape=(180,) dtype=float32_ref>,\n",
       " <tf.Variable 'bfc1:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'bfc2:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'bfc3:0' shape=(12,) dtype=float32_ref>,\n",
       " <tf.Variable 'beta1_power:0' shape=() dtype=float32_ref>,\n",
       " <tf.Variable 'beta2_power:0' shape=() dtype=float32_ref>,\n",
       " <tf.Variable 'wconv1/Adam:0' shape=(61, 8, 1, 180) dtype=float32_ref>,\n",
       " <tf.Variable 'wconv1/Adam_1:0' shape=(61, 8, 1, 180) dtype=float32_ref>,\n",
       " <tf.Variable 'wfc1/Adam:0' shape=(167400, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'wfc1/Adam_1:0' shape=(167400, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'wfc2/Adam:0' shape=(128, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'wfc2/Adam_1:0' shape=(128, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'wfc3/Adam:0' shape=(128, 12) dtype=float32_ref>,\n",
       " <tf.Variable 'wfc3/Adam_1:0' shape=(128, 12) dtype=float32_ref>,\n",
       " <tf.Variable 'bconv1/Adam:0' shape=(180,) dtype=float32_ref>,\n",
       " <tf.Variable 'bconv1/Adam_1:0' shape=(180,) dtype=float32_ref>,\n",
       " <tf.Variable 'bfc1/Adam:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'bfc1/Adam_1:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'bfc2/Adam:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'bfc2/Adam_1:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'bfc3/Adam:0' shape=(12,) dtype=float32_ref>,\n",
       " <tf.Variable 'bfc3/Adam_1:0' shape=(12,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.global_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'wconv1:0' shape=(61, 8, 1, 180) dtype=float32_ref>,\n",
       " <tf.Variable 'wfc1:0' shape=(167400, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'wfc2:0' shape=(128, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'wfc3:0' shape=(128, 12) dtype=float32_ref>,\n",
       " <tf.Variable 'bconv1:0' shape=(180,) dtype=float32_ref>,\n",
       " <tf.Variable 'bfc1:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'bfc2:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'bfc3:0' shape=(12,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TRAINING\n",
    "def run_optimize(num_iterations, logs_path, min_loss=0):\n",
    "    # Start-time\n",
    "    start_time = time.time()\n",
    "    msg = \"\\n====================\\nStarting training...\\n====================\"\n",
    "    tf.logging.info(msg)\n",
    "    \n",
    "    df = load_data(cfg.DATA_DIR)\n",
    "\n",
    "    w = 1850. / 32550.\n",
    "    tf.logging.info(\"Begin iterations...\")\n",
    "    for i in xrange(num_iterations):\n",
    "        \n",
    "        # Get the training batch\n",
    "        X_train, y_true_batch = load_batch(df, cfg.DATA_DIR,\n",
    "                                           batch_size=batch_size, silence_size=silence_size,\n",
    "                                           label='train',\n",
    "                                           random=True, seed=None,\n",
    "                                           w=w, samples=cfg.SAMRATE)\n",
    "        \n",
    "        # Preprocess the training batch\n",
    "        x_mfcc_batch, x_mel_batch, x_zcr_batch, x_rmse_batch = sess.run(\n",
    "            [x_mfcc, x_mel, x_zcr, x_rmse],\n",
    "            feed_dict={X_data: X_train,\n",
    "                       noise_factor: noise_factor_value,\n",
    "                       noise_frac: noise_frac_value})\n",
    "\n",
    "        # Training optimization\n",
    "        sess.run(optimizer, feed_dict={x_mel: x_mel_batch,\n",
    "                                       x_mfcc: x_mfcc_batch,\n",
    "                                       x_zcr: x_zcr_batch,\n",
    "                                       x_rmse: x_rmse_batch, \n",
    "                                       y_true: y_true_batch,\n",
    "                                       dropout_prob: dropout_prob_value,\n",
    "                                       is_training: True})\n",
    "        \n",
    "        # Checkpoint save and validation step\n",
    "        if ((i + 1) % checkpoint_step == 0) or (i == num_iterations - 1):\n",
    "            \n",
    "            # Checkpoint\n",
    "            checkpoint_path = os.path.join(logs_path, 'model.ckpt')\n",
    "            msg = \"Saving checkpoint to: {}-{}\"\n",
    "            tf.logging.info(msg.format(checkpoint_path, i + 1))\n",
    "            saver.save(sess, checkpoint_path, global_step=i + 1)\n",
    "            \n",
    "            # Load the validation batches\n",
    "            val_batch_size = 100\n",
    "            total_val_accuracy = 0\n",
    "            total_conf_matrix = None\n",
    "            set_size = 6700\n",
    "            for j in xrange(0, set_size, val_batch_size):\n",
    "                X_val, y_true_val = load_batch(df, cfg.DATA_DIR,\n",
    "                                               batch_size=val_batch_size, silence_size=silence_size,\n",
    "                                               label='val',\n",
    "                                               random=False, seed=j,\n",
    "                                               w=1.0, samples=cfg.SAMRATE)\n",
    "    \n",
    "                # Preprocess the validation batch\n",
    "                x_mfcc_val, x_mel_val, x_zcr_val, x_rmse_val = sess.run(\n",
    "                    [x_mfcc, x_mel, x_zcr, x_rmse],\n",
    "                    feed_dict = {X_data: X_val,\n",
    "                                 noise_factor: 0.0,\n",
    "                                 noise_frac: 0.0})\n",
    "                \n",
    "                # Validation summary\n",
    "                val_summary, loss_val, acc_val, conf_matrix = sess.run(\n",
    "                    [merged, loss, accuracy, confusion_matrix],\n",
    "                    feed_dict={x_mel: x_mel_val,\n",
    "                               x_mfcc: x_mfcc_val,\n",
    "                               x_zcr: x_zcr_val,\n",
    "                               x_rmse: x_rmse_val,\n",
    "                               y_true: y_true_val,\n",
    "                               dropout_prob: 1.0,\n",
    "                               is_training: False})\n",
    "                total_val_accuracy += (acc_val * val_batch_size) / set_size\n",
    "                if total_conf_matrix is None:\n",
    "                    total_conf_matrix = conf_matrix\n",
    "                else:\n",
    "                    total_conf_matrix += conf_matrix\n",
    "            \n",
    "            msg = \"Confusion Matrix:\\n {}\"\n",
    "            tf.logging.info(msg.format(total_conf_matrix))\n",
    "            msg = \"VALIDATION ACC: {:6f}, (N = {})\"\n",
    "            tf.logging.info(msg.format(total_val_accuracy, set_size))\n",
    "\n",
    "        # Display step\n",
    "        if (i == 0) or ((i + 1) % display_step == 0) or (i == num_iterations - 1):\n",
    "            # Training summary, loss and accuracy\n",
    "            train_summary, loss_train, acc_train = sess.run(\n",
    "                [merged, loss, accuracy],\n",
    "                feed_dict={x_mel: x_mel_batch,\n",
    "                           x_mfcc: x_mfcc_batch,\n",
    "                           x_zcr: x_zcr_batch,\n",
    "                           x_rmse: x_rmse_batch,\n",
    "                           y_true: y_true_batch,\n",
    "                           dropout_prob: 1.0,\n",
    "                           is_training: False})\n",
    "            train_writer.add_summary(train_summary, i + 1)\n",
    "            \n",
    "            # Display message\n",
    "            msg = \"  OPTIMIZE STEP: {:6d}, LOSS, {:.6f}, ACC: {:.6f}\"\n",
    "            tf.logging.info(msg.format(i + 1, loss_train, acc_train))\n",
    "    \n",
    "            # Check if loss is below minimum\n",
    "            if loss_train < min_loss:\n",
    "                break\n",
    "    \n",
    "    # End-time\n",
    "    end_time = time.time()\n",
    "    msg = \"Time usage: {}\"\n",
    "    tf.logging.info(msg.format(timedelta(seconds=int(round(end_time - start_time)))))\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Run Training (short test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Initialize\n",
    "reset_vars()\n",
    "\n",
    "# Set path to summary logs\n",
    "now = datetime.now()\n",
    "logs_path = os.path.join(cfg.OUT_DIR, now.strftime(\"%Y%m%d-%H%M%S\"), 'summaries')\n",
    "\n",
    "# Create summary writers\n",
    "train_writer = tf.summary.FileWriter(os.path.join(logs_path, 'train'), graph=tf.get_default_graph())\n",
    "test_writer = tf.summary.FileWriter(os.path.join(logs_path, 'test'), graph=tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:\n",
      "====================\n",
      "Starting training...\n",
      "====================\n",
      "INFO:tensorflow:Begin iterations...\n",
      "INFO:tensorflow:  OPTIMIZE STEP:      1, LOSS, 3.132832, ACC: 0.125000\n",
      "INFO:tensorflow:  OPTIMIZE STEP:    100, LOSS, 2.648787, ACC: 0.101562\n",
      "INFO:tensorflow:  OPTIMIZE STEP:    200, LOSS, 4.539347, ACC: 0.117188\n",
      "INFO:tensorflow:  OPTIMIZE STEP:    300, LOSS, 4.593124, ACC: 0.070312\n",
      "INFO:tensorflow:  OPTIMIZE STEP:    400, LOSS, 8.636628, ACC: 0.078125\n",
      "INFO:tensorflow:Saving checkpoint to: ./models/20171213-195259/summaries.ckpt-500\n",
      "INFO:tensorflow:Confusion Matrix:\n",
      " [[  19  111 1258    0   83    0  150 1189    0  939  162   48]\n",
      " [   1   12   67    0    7    0   10   81    0   57   17    1]\n",
      " [   1   12   83    0    4    0   10   75    0   59    8    6]\n",
      " [   4   13   80    0    6    0    4   61    0   45   23   12]\n",
      " [   0    6   71    0    5    0   19   82    0   58    8    3]\n",
      " [   1    4   63    0    9    0    7   85    0   55    9    6]\n",
      " [   0   12   80    0   13    0    7   80    0   40    8    8]\n",
      " [   1    7   72    0    4    0   10   71    0   64   11    5]\n",
      " [   2    6   82    0    6    0    9   74    0   47   11    7]\n",
      " [   0    4   81    0   10    0    8   77    0   43    8    3]\n",
      " [   1    9   89    0    6    0   15   63    0   56    8    5]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0  268]]\n",
      "INFO:tensorflow:VALIDATION ACC: 0.077015, (N = 6700)\n",
      "INFO:tensorflow:  OPTIMIZE STEP:    500, LOSS, 12.361126, ACC: 0.117188\n",
      "INFO:tensorflow:  OPTIMIZE STEP:    600, LOSS, 2.914118, ACC: 0.093750\n",
      "INFO:tensorflow:  OPTIMIZE STEP:    700, LOSS, 3.439095, ACC: 0.132812\n",
      "INFO:tensorflow:  OPTIMIZE STEP:    800, LOSS, 3.398471, ACC: 0.132812\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-9a3154f8f430>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_optimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-45-8b8a7b564ac6>\u001b[0m in \u001b[0;36mrun_optimize\u001b[0;34m(num_iterations, logs_path, min_loss)\u001b[0m\n\u001b[1;32m     33\u001b[0m                                        \u001b[0my_true\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_true_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                                        \u001b[0mdropout_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdropout_prob_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                                        is_training: True})\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# Checkpoint save and validation step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_optimize(num_iterations, logs_path, min_loss=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cfg.NUM2LABEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fname = os.path.join(cfg.DATA_DIR, 'noise_clips', 'noise_clips.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "nf = tf.gfile.FastGFile(fname, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "nflines = nf.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "nfarr = np.array([np.fromstring(l, sep=',') for l in nflines])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.71797845, -0.86306345, -1.        , ...,  0.00793481,\n",
       "         0.01596118,  0.13812677],\n",
       "       [ 0.27036348,  0.14755699,  0.15768914, ..., -0.09686575,\n",
       "        -0.24463637, -0.36512345],\n",
       "       [-0.06485183, -0.15851314,  0.07629627, ...,  0.16415906,\n",
       "         0.09308145, -0.06280709],\n",
       "       ..., \n",
       "       [ 0.10189928, -0.0955158 ,  0.17062022, ..., -0.14555915,\n",
       "         0.42666877,  0.44093309],\n",
       "       [-0.15319491, -0.18576196,  0.02255593, ..., -0.15782969,\n",
       "         0.00407861, -0.10950439],\n",
       "       [-0.07755269,  0.07310942,  0.18612061, ...,  0.10655091,\n",
       "         0.27504458,  0.18682218]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nfarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from scipy.io import wavfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "testfile = 'data/train/audio/bed/0a7c2a8d_nohash_0.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = tf.gfile.GFile(testfile, 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, array([ -1, -22, -29, ..., -22, -18, -18], dtype=int16))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wavfile.read(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
