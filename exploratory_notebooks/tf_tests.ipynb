{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load custom libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config as cfg\n",
    "from dataload import load_data, load_batch\n",
    "from preprocessing import signalProcessBatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow setup\n",
    "sess = None\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "def reset_vars():\n",
    "    \"\"\"Initializes all tf variables\"\"\"\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "def reset_tf():\n",
    "    \"\"\"Closes the current tf session and opens new session\"\"\"\n",
    "    global sess\n",
    "    if sess:\n",
    "        sess.close()\n",
    "    tf.reset_default_graph()\n",
    "    sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to initialize weights and biases\n",
    "def weight_variable(shape, name):\n",
    "    \"\"\"Creates a variable of size shape with random small positive numbers\"\"\"\n",
    "    initial = tf.truncated_normal(shape, stddev=0.01)\n",
    "    return tf.Variable(initial, name=name)\n",
    "\n",
    "\n",
    "def bias_variable(shape, name):\n",
    "    \"\"\"Creates a variable of size shape with a constant small positive number\"\"\"\n",
    "    initial = tf.constant(0.01, shape=shape)\n",
    "    return tf.Variable(initial, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conv2d, max pooling, and dropout wrapper functions for simplicity (No padding)\n",
    "def conv2d(x, W, sx=1, sy=1):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, sx, sy, 1], padding='VALID')\n",
    "\n",
    "\n",
    "def max_pool_2d(x, k=2):\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='VALID')\n",
    "\n",
    "\n",
    "def dropout(x, d, is_training):\n",
    "    if is_training is not None:\n",
    "        return tf.nn.dropout(x, d)\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_tf()\n",
    "\n",
    "# Model parameters\n",
    "melspec_shape = (122, 64)                           # Shape of Mel spectrum data (t x f)\n",
    "melspec_size = melspec_shape[0] * melspec_shape[1]\n",
    "mfcc_shape = (122, 13)                              # Shape of MFCC data (t x mfcc)\n",
    "mfcc_size = mfcc_shape[0] * mfcc_shape[1]\n",
    "sf_size = 122                                       # Length of 1D feature arrays e.g. ZCR and RMSE\n",
    "\n",
    "n_classes = len(cfg.NUM2LABEL)\n",
    "\n",
    "batch_size = 128\n",
    "silence_size = 4\n",
    "num_iterations = 200\n",
    "display_step = 10\n",
    "checkpoint_step = 100\n",
    "\n",
    "learning_rate = 5e-4\n",
    "dropout_prob_value = 0.50                           # Dropout, probability to keep units\n",
    "\n",
    "noise_factor_value = 0.1\n",
    "noise_frac_value = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total feature size:  9516\n"
     ]
    }
   ],
   "source": [
    "print \"Total feature size:  {}\".format(melspec_size + mfcc_size + sf_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL\n",
    "def conv_net_speech_model(x_mel_in, x_mfcc_in, x_zcr_in, x_rmse_in, dropout_prob=None, is_training=False):\n",
    "    \n",
    "    #======================================================\n",
    "    # Setup the parameters for the model\n",
    "    #======================================================\n",
    "    \n",
    "    # Mel Spectrogram input size\n",
    "    t_size = melspec_shape[0]\n",
    "    f_size = melspec_shape[1]\n",
    "\n",
    "    # Parameters for Conv layer 1 filter\n",
    "    filter_size_t = 61\n",
    "    filter_size_f = 8\n",
    "    filter_count = 180\n",
    "    filter_stride_t = 1\n",
    "    filter_stride_f = 4\n",
    "    \n",
    "    # Paramaters for FC layers\n",
    "    fc_output_channels_1 = 128\n",
    "    fc_output_channels_2 = 128\n",
    "    fc_output_channels_3 = n_classes\n",
    "    \n",
    "    # Number of elements in the first FC layer\n",
    "    fc_element_count = int(filter_count \\\n",
    "                       * int(1 + (t_size - filter_size_t) / filter_stride_t) \\\n",
    "                       * int(1 + (f_size - filter_size_f) / filter_stride_f))\n",
    "    \n",
    "    #======================================================\n",
    "    # Setup dictionaries containing weights and biases\n",
    "    #======================================================\n",
    "    \n",
    "    weights = {\n",
    "        'wconv1': weight_variable([filter_size_t, filter_size_f, 1, filter_count], 'wconv1'),\n",
    "        'wfc1': weight_variable([fc_element_count, fc_output_channels_1], 'wfc1'),\n",
    "        'wfc2': weight_variable([fc_output_channels_1, fc_output_channels_2], 'wfc2'),\n",
    "        'wfc3': weight_variable([fc_output_channels_2, fc_output_channels_3], 'wfc3'),\n",
    "    }\n",
    "    biases = {\n",
    "        'bconv1': bias_variable([filter_count], 'bconv1'),\n",
    "        'bfc1': bias_variable([fc_output_channels_1], 'bfc1'),\n",
    "        'bfc2': bias_variable([fc_output_channels_2], 'bfc2'),\n",
    "        'bfc3': bias_variable([fc_output_channels_3], 'bfc3'),\n",
    "    }\n",
    "    \n",
    "    #======================================================\n",
    "    # Model definition and calculations\n",
    "    #======================================================\n",
    "    \n",
    "    # Reshape input to [audio file number, time size, freq size, channel]\n",
    "    x_mel_rs = tf.reshape(x_mel_in, [-1, t_size, f_size, 1])\n",
    "    \n",
    "    # Layer 1: first Conv layer, BiasAdd and ReLU\n",
    "    x_mel_1 = tf.nn.relu(conv2d(x_mel_rs, weights['wconv1'],\n",
    "                                sx=filter_stride_t,\n",
    "                                sy=filter_stride_f) + biases['bconv1'])\n",
    "\n",
    "    # Dropout 1:\n",
    "    x_mel_dropout_1 = dropout(x_mel_1, dropout_prob, is_training)\n",
    "    \n",
    "    # Flatten layers\n",
    "    x_mel_1_rs = tf.reshape(x_mel_dropout_1, [-1, fc_element_count])\n",
    "\n",
    "    # Layer 2: first FC layer\n",
    "    x_mel_2 = tf.matmul(x_mel_1_rs, weights['wfc1']) + biases['bfc1']\n",
    "    \n",
    "    # Dropout 2:\n",
    "    x_mel_dropout_2 = dropout(x_mel_2, dropout_prob, is_training)\n",
    "    \n",
    "    # Layer 3: second FC layer\n",
    "    x_mel_3 = tf.matmul(x_mel_dropout_2, weights['wfc2']) + biases['bfc2']\n",
    "    \n",
    "    # Dropout 3:\n",
    "    x_mel_dropout_3 = dropout(x_mel_3, dropout_prob, is_training)\n",
    "    \n",
    "    # Layer 4: third FC layer\n",
    "    x_mel_output = tf.matmul(x_mel_dropout_3, weights['wfc3']) + biases['bfc3']\n",
    "    \n",
    "    return x_mel_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholders for signals preprocessing inputs\n",
    "X_data = tf.placeholder(tf.float32, [None, cfg.SAMRATE], name='X_data')\n",
    "\n",
    "noise_factor = tf.placeholder(tf.float32, shape=(), name='noise_factor')\n",
    "noise_frac = tf.placeholder(tf.float32, shape=(), name='noise_frac')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the audio features\n",
    "x_mfcc, x_mel, x_zcr, x_rmse = signalProcessBatch(X_data,\n",
    "                                                  noise_factor=noise_factor,\n",
    "                                                  noise_frac=noise_frac,\n",
    "                                                  window=512,\n",
    "                                                  maxamps=cfg.MAXAMPS, sr=cfg.SAMRATE,\n",
    "                                                  num_mel_bins=64, num_mfccs=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder variables output (1-hot vectors of size n_classes)\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, n_classes], name='y_true')\n",
    "y_true_class = tf.argmax(y_true, 1, name='y_true_class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropout keep probability and training flag\n",
    "dropout_prob = tf.placeholder(tf.float32, shape=(), name='dropout_prob')\n",
    "is_training = tf.placeholder(tf.bool, name=\"is_training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction from model\n",
    "y_pred = conv_net_speech_model(x_mel, x_mfcc, x_zcr, x_rmse, dropout_prob=dropout_prob, is_training=is_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'accuracy:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross entropy loss function with softmax then takes mean\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_pred, labels=y_true))\n",
    "tf.summary.scalar('loss', loss)\n",
    "\n",
    "# Train and backprop gradients function\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "# Evaluation and accuracy\n",
    "y_pred_class = tf.argmax(y_pred, 1, name='y_pred_class')\n",
    "correct_prediction = tf.equal(y_pred_class, y_true_class)\n",
    "confusion_matrix = tf.confusion_matrix(y_true_class, y_pred_class, num_classes=n_classes)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "tf.summary.scalar('accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all summaries\n",
    "merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saver for checkpoints\n",
    "saver = tf.train.Saver(tf.global_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'wconv1:0' shape=(61, 8, 1, 180) dtype=float32_ref>,\n",
       " <tf.Variable 'wfc1:0' shape=(167400, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'wfc2:0' shape=(128, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'wfc3:0' shape=(128, 12) dtype=float32_ref>,\n",
       " <tf.Variable 'bconv1:0' shape=(180,) dtype=float32_ref>,\n",
       " <tf.Variable 'bfc1:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'bfc2:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'bfc3:0' shape=(12,) dtype=float32_ref>,\n",
       " <tf.Variable 'beta1_power:0' shape=() dtype=float32_ref>,\n",
       " <tf.Variable 'beta2_power:0' shape=() dtype=float32_ref>,\n",
       " <tf.Variable 'wconv1/Adam:0' shape=(61, 8, 1, 180) dtype=float32_ref>,\n",
       " <tf.Variable 'wconv1/Adam_1:0' shape=(61, 8, 1, 180) dtype=float32_ref>,\n",
       " <tf.Variable 'wfc1/Adam:0' shape=(167400, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'wfc1/Adam_1:0' shape=(167400, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'wfc2/Adam:0' shape=(128, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'wfc2/Adam_1:0' shape=(128, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'wfc3/Adam:0' shape=(128, 12) dtype=float32_ref>,\n",
       " <tf.Variable 'wfc3/Adam_1:0' shape=(128, 12) dtype=float32_ref>,\n",
       " <tf.Variable 'bconv1/Adam:0' shape=(180,) dtype=float32_ref>,\n",
       " <tf.Variable 'bconv1/Adam_1:0' shape=(180,) dtype=float32_ref>,\n",
       " <tf.Variable 'bfc1/Adam:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'bfc1/Adam_1:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'bfc2/Adam:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'bfc2/Adam_1:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'bfc3/Adam:0' shape=(12,) dtype=float32_ref>,\n",
       " <tf.Variable 'bfc3/Adam_1:0' shape=(12,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.global_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'wconv1:0' shape=(61, 8, 1, 180) dtype=float32_ref>,\n",
       " <tf.Variable 'wfc1:0' shape=(167400, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'wfc2:0' shape=(128, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'wfc3:0' shape=(128, 12) dtype=float32_ref>,\n",
       " <tf.Variable 'bconv1:0' shape=(180,) dtype=float32_ref>,\n",
       " <tf.Variable 'bfc1:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'bfc2:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'bfc3:0' shape=(12,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING\n",
    "def run_optimize(num_iterations, logs_path, min_loss=0):\n",
    "    # Start-time\n",
    "    start_time = time.time()\n",
    "    msg = \"\\n====================\\nStarting training...\\n====================\"\n",
    "    tf.logging.info(msg)\n",
    "    \n",
    "    df = load_data(cfg.DATA_DIR)\n",
    "\n",
    "    w = 0.075\n",
    "    tf.logging.info(\"Begin iterations...\")\n",
    "    for i in xrange(num_iterations):\n",
    "        \n",
    "        # Get the training batch\n",
    "        X_train, y_true_batch = load_batch(df, cfg.DATA_DIR,\n",
    "                                           batch_size=batch_size, silence_size=silence_size,\n",
    "                                           label='train',\n",
    "                                           random=True, seed=None,\n",
    "                                           w=w, samples=cfg.SAMRATE)\n",
    "        \n",
    "        # Preprocess the training batch\n",
    "        x_mfcc_batch, x_mel_batch, x_zcr_batch, x_rmse_batch = sess.run(\n",
    "            [x_mfcc, x_mel, x_zcr, x_rmse],\n",
    "            feed_dict={X_data: X_train,\n",
    "                       noise_factor: noise_factor_value,\n",
    "                       noise_frac: noise_frac_value})\n",
    "\n",
    "        # Training optimization\n",
    "        sess.run(optimizer, feed_dict={x_mel: x_mel_batch,\n",
    "                                       x_mfcc: x_mfcc_batch,\n",
    "                                       x_zcr: x_zcr_batch,\n",
    "                                       x_rmse: x_rmse_batch, \n",
    "                                       y_true: y_true_batch,\n",
    "                                       dropout_prob: dropout_prob_value,\n",
    "                                       is_training: True})\n",
    "        \n",
    "        # Checkpoint save and validation step\n",
    "        if ((i + 1) % checkpoint_step == 0) or (i == num_iterations - 1):\n",
    "            \n",
    "            # Checkpoint\n",
    "            checkpoint_path = os.path.join(logs_path, 'model.ckpt')\n",
    "            msg = \"Saving checkpoint to: {}-{}\"\n",
    "            tf.logging.info(msg.format(checkpoint_path, i + 1))\n",
    "            saver.save(sess, checkpoint_path, global_step=i + 1)\n",
    "            \n",
    "            # Load the validation batches\n",
    "            val_batch_size = 100\n",
    "            total_val_accuracy = 0\n",
    "            total_conf_matrix = None\n",
    "            set_size = 6700\n",
    "            for j in xrange(0, set_size, val_batch_size):\n",
    "                X_val, y_true_val = load_batch(df, cfg.DATA_DIR,\n",
    "                                               batch_size=val_batch_size, silence_size=silence_size,\n",
    "                                               label='val',\n",
    "                                               random=False, seed=j,\n",
    "                                               w=1.0, samples=cfg.SAMRATE)\n",
    "    \n",
    "                # Preprocess the validation batch\n",
    "                x_mfcc_val, x_mel_val, x_zcr_val, x_rmse_val = sess.run(\n",
    "                    [x_mfcc, x_mel, x_zcr, x_rmse],\n",
    "                    feed_dict = {X_data: X_val,\n",
    "                                 noise_factor: 0.0,\n",
    "                                 noise_frac: 0.0})\n",
    "                \n",
    "                # Validation summary\n",
    "                val_summary, loss_val, acc_val, conf_matrix = sess.run(\n",
    "                    [merged, loss, accuracy, confusion_matrix],\n",
    "                    feed_dict={x_mel: x_mel_val,\n",
    "                               x_mfcc: x_mfcc_val,\n",
    "                               x_zcr: x_zcr_val,\n",
    "                               x_rmse: x_rmse_val,\n",
    "                               y_true: y_true_val,\n",
    "                               dropout_prob: 1.0,\n",
    "                               is_training: False})\n",
    "                total_val_accuracy += (acc_val * val_batch_size) / set_size\n",
    "                if total_conf_matrix is None:\n",
    "                    total_conf_matrix = conf_matrix\n",
    "                else:\n",
    "                    total_conf_matrix += conf_matrix\n",
    "            \n",
    "            msg = \"Confusion Matrix:\\n {}\"\n",
    "            tf.logging.info(msg.format(total_conf_matrix))\n",
    "            msg = \"VALIDATION ACC: {:6f}, (N = {})\"\n",
    "            tf.logging.info(msg.format(total_val_accuracy, set_size))\n",
    "\n",
    "        # Display step\n",
    "        if (i == 0) or ((i + 1) % display_step == 0) or (i == num_iterations - 1):\n",
    "            # Training summary, loss and accuracy\n",
    "            train_summary, loss_train, acc_train = sess.run(\n",
    "                [merged, loss, accuracy],\n",
    "                feed_dict={x_mel: x_mel_batch,\n",
    "                           x_mfcc: x_mfcc_batch,\n",
    "                           x_zcr: x_zcr_batch,\n",
    "                           x_rmse: x_rmse_batch,\n",
    "                           y_true: y_true_batch,\n",
    "                           dropout_prob: 1.0,\n",
    "                           is_training: False})\n",
    "            train_writer.add_summary(train_summary, i + 1)\n",
    "            \n",
    "            # Display message\n",
    "            msg = \"  OPTIMIZE STEP: {:6d}, LOSS, {:.6f}, ACC: {:.6f}\"\n",
    "            tf.logging.info(msg.format(i + 1, loss_train, acc_train))\n",
    "    \n",
    "            # Check if loss is below minimum\n",
    "            if loss_train < min_loss:\n",
    "                break\n",
    "    \n",
    "    # End-time\n",
    "    end_time = time.time()\n",
    "    msg = \"Time usage: {}\"\n",
    "    tf.logging.info(msg.format(timedelta(seconds=int(round(end_time - start_time)))))\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Training (short test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "reset_vars()\n",
    "\n",
    "# Set path to summary logs\n",
    "now = datetime.now()\n",
    "logs_path = os.path.join(cfg.OUT_DIR, now.strftime(\"%Y%m%d-%H%M%S\"), 'summaries')\n",
    "\n",
    "# Create summary writers\n",
    "train_writer = tf.summary.FileWriter(os.path.join(logs_path, 'train'), graph=tf.get_default_graph())\n",
    "test_writer = tf.summary.FileWriter(os.path.join(logs_path, 'test'), graph=tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:\n",
      "====================\n",
      "Starting training...\n",
      "====================\n",
      "INFO:tensorflow:Begin iterations...\n",
      "INFO:tensorflow:  OPTIMIZE STEP:      1, LOSS, 3.348485, ACC: 0.140625\n",
      "INFO:tensorflow:  OPTIMIZE STEP:     10, LOSS, 2.487481, ACC: 0.156250\n",
      "INFO:tensorflow:  OPTIMIZE STEP:     20, LOSS, 2.438335, ACC: 0.140625\n",
      "INFO:tensorflow:  OPTIMIZE STEP:     30, LOSS, 2.671888, ACC: 0.125000\n",
      "INFO:tensorflow:  OPTIMIZE STEP:     40, LOSS, 2.434289, ACC: 0.117188\n",
      "INFO:tensorflow:  OPTIMIZE STEP:     50, LOSS, 4.500966, ACC: 0.093750\n",
      "INFO:tensorflow:  OPTIMIZE STEP:     60, LOSS, 2.481188, ACC: 0.132812\n",
      "INFO:tensorflow:  OPTIMIZE STEP:     70, LOSS, 3.206299, ACC: 0.164062\n",
      "INFO:tensorflow:  OPTIMIZE STEP:     80, LOSS, 2.535654, ACC: 0.117188\n",
      "INFO:tensorflow:  OPTIMIZE STEP:     90, LOSS, 2.693345, ACC: 0.085938\n",
      "INFO:tensorflow:Saving checkpoint to: ../models/20180215-125515/summaries/model.ckpt-100\n",
      "INFO:tensorflow:Confusion Matrix:\n",
      " [[   0    0   46  280    0 1075 1682  166   18  234  316  142]\n",
      " [   0    0    4    9    0   57  135   10    0   19   10    9]\n",
      " [   0    0    2   20    0   45  120   16    0   11   28   16]\n",
      " [   0    0    8   40    0   54   73   13    1   12   23   24]\n",
      " [   0    0    2   20    0   57  119    9    1   20   19    5]\n",
      " [   0    0    5   21    0   62  102    6    1   14   14   14]\n",
      " [   0    0    6   19    0   46  111    9    1   12   25   19]\n",
      " [   0    0    3   22    0   72   91    8    3   16   20   10]\n",
      " [   0    0    3    9    0   71   91   12    5   20   21   12]\n",
      " [   0    0    2   34    0   51   82    9    0   24   21   11]\n",
      " [   0    0    7   13    0   53  114    9    1   15   29   11]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0  268]]\n",
      "INFO:tensorflow:VALIDATION ACC: 0.081940, (N = 6700)\n",
      "INFO:tensorflow:  OPTIMIZE STEP:    100, LOSS, 3.196885, ACC: 0.125000\n",
      "INFO:tensorflow:  OPTIMIZE STEP:    110, LOSS, 3.868408, ACC: 0.148438\n",
      "INFO:tensorflow:  OPTIMIZE STEP:    120, LOSS, 2.478256, ACC: 0.101562\n",
      "INFO:tensorflow:  OPTIMIZE STEP:    130, LOSS, 2.515620, ACC: 0.117188\n",
      "INFO:tensorflow:  OPTIMIZE STEP:    140, LOSS, 4.659041, ACC: 0.156250\n",
      "INFO:tensorflow:  OPTIMIZE STEP:    150, LOSS, 2.825246, ACC: 0.093750\n",
      "INFO:tensorflow:  OPTIMIZE STEP:    160, LOSS, 4.174566, ACC: 0.039062\n",
      "INFO:tensorflow:  OPTIMIZE STEP:    170, LOSS, 2.518996, ACC: 0.101562\n",
      "INFO:tensorflow:  OPTIMIZE STEP:    180, LOSS, 3.585473, ACC: 0.109375\n",
      "INFO:tensorflow:  OPTIMIZE STEP:    190, LOSS, 22.073170, ACC: 0.039062\n",
      "INFO:tensorflow:Saving checkpoint to: ../models/20180215-125515/summaries/model.ckpt-200\n",
      "INFO:tensorflow:Confusion Matrix:\n",
      " [[3262    0    0    0    0    0   72    0    0  586    0   39]\n",
      " [ 229    0    0    0    0    0    8    0    0   13    0    3]\n",
      " [ 213    0    0    0    0    0    9    0    0   31    0    5]\n",
      " [ 196    0    0    0    0    0   12    0    0   33    0    7]\n",
      " [ 220    0    0    0    0    0    5    0    0   26    0    1]\n",
      " [ 214    0    0    0    0    0    3    0    0   20    0    2]\n",
      " [ 210    0    0    0    0    0    8    0    0   28    0    2]\n",
      " [ 188    0    0    0    0    0    6    0    0   45    0    6]\n",
      " [ 214    0    0    0    0    0    1    0    0   24    0    5]\n",
      " [ 189    0    0    0    0    0    1    0    0   40    0    4]\n",
      " [ 212    0    0    0    0    0    6    0    0   32    0    2]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0  268]]\n",
      "INFO:tensorflow:VALIDATION ACC: 0.534030, (N = 6700)\n",
      "INFO:tensorflow:  OPTIMIZE STEP:    200, LOSS, 4.058626, ACC: 0.117188\n",
      "INFO:tensorflow:Time usage: 0:17:28\n"
     ]
    }
   ],
   "source": [
    "run_optimize(num_iterations, logs_path, min_loss=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
